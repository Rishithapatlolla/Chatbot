{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"rag.py\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1gPulzDgzZ1D2TSlNOCbgW2ZHKdPTYt3A\n",
        "\"\"\"\n",
        "\n",
        "!pip install pytesseract\n",
        "!pip install -U langchain-community\n",
        "!pip install google-cloud-translate==2.0.0\n",
        "!pip install pdfplumber\n",
        "!pip install httpx==0.28.1\n",
        "!pip install langchain-huggingface sentence-transformers transformers faiss-cpu pytesseract pdfplumber googletrans websockets deep_translator\n",
        "# Colab: install libs\n",
        "!pip install  faiss-cpu PyPDF2 pdfplumber flask flask_cors pyngrok\n",
        "!pip install falcon\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "import torch\n",
        "import pdfplumber\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "from deep_translator import GoogleTranslator\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "from langchain_core.documents import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# Path to your zip file\n",
        "zip_path = \"/content/doc_files.zip\"\n",
        "\n",
        "# Directory to extract files\n",
        "extract_dir = \"/content/extracted_files\" # Changed directory name\n",
        "\n",
        "# Create extraction directory if it doesn't exist\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Extract zip contents\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(f\"Files extracted to: {extract_dir}\")\n",
        "print(\"Files:\")\n",
        "print(os.listdir(extract_dir))"
      ],
      "metadata": {
        "id": "VQstyM7h0f88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "842b4720"
      },
      "source": [
        "# -------- Document Processor --------\n",
        "class DocumentProcessor:\n",
        "    def __init__(self):\n",
        "        self.ocr_lang = 'eng+ara'\n",
        "        self.translator_en = GoogleTranslator(source='auto', target='en')\n",
        "        self.translator_ar = GoogleTranslator(source='auto', target='ar')\n",
        "\n",
        "    def extract_text_from_pdf(self, filepath):\n",
        "        text = \"\"\n",
        "        with pdfplumber.open(filepath) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += page_text + \"\\n\"\n",
        "        return text\n",
        "\n",
        "    def extract_text_from_image(self, filepath):\n",
        "        return pytesseract.image_to_string(Image.open(filepath), lang=self.ocr_lang)\n",
        "\n",
        "    def extract_text_from_txt(self, filepath):\n",
        "        with open(filepath, 'r', encoding='utf-8') as f:\n",
        "            return f.read()\n",
        "\n",
        "    def extract_text_from_md(self, filepath):\n",
        "        with open(filepath, 'r', encoding='utf-8') as f:\n",
        "            return f.read()\n",
        "\n",
        "\n",
        "    def translate_text_in_chunks(self, text, dest='en', chunk_size=4000):\n",
        "        translated_text = \"\"\n",
        "        translator = self.translator_en if dest == 'en' else self.translator_ar\n",
        "        for i in range(0, len(text), chunk_size):\n",
        "            chunk = text[i:i + chunk_size]\n",
        "            try:\n",
        "                translated_text += translator.translate(chunk)\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Error translating chunk: {e}\")\n",
        "                translated_text += chunk\n",
        "        return translated_text\n",
        "\n",
        "    def process_document(self, filepath, filetype='pdf'):\n",
        "        text = \"\"\n",
        "        if filetype == 'pdf':\n",
        "            text = self.extract_text_from_pdf(filepath)\n",
        "        elif filetype == 'txt':\n",
        "            text = self.extract_text_from_txt(filepath)\n",
        "        elif filetype == 'md':\n",
        "            text = self.extract_text_from_md(filepath)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported file type: {filetype}\")\n",
        "\n",
        "\n",
        "        text_en = self.translate_text_in_chunks(text, dest='en')\n",
        "        summary_en = \"Summarization disabled\"\n",
        "        summary_ar = \"Summarization disabled\"\n",
        "        return text, text_en, summary_en, summary_ar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed1ac32c"
      },
      "source": [
        "# -------- Department Tagger --------\n",
        "class DepartmentTagger:\n",
        "    def __init__(self):\n",
        "        self.keywords = {\n",
        "            \"Finance\": [\"budget\", \"revenue\", \"expense\", \"finance\"],\n",
        "            \"Currency\": [\"banknotes\", \"coins\", \"mint\", \"currency\"],\n",
        "            \"IT\": [\"network\", \"software\", \"hardware\", \"technology\", \"it\"],\n",
        "            \"Legal\": [\"regulation\", \"law\", \"compliance\", \"legal\"]\n",
        "        }\n",
        "\n",
        "    def tag(self, text):\n",
        "        txt = text.lower()\n",
        "        return [dept for dept, kws in self.keywords.items() if any(kw in txt for kw in kws)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ab0df57"
      },
      "source": [
        "# -------- LLM Setup --------\n",
        "def get_llm():\n",
        "    # The Falcon-H1-1B-Base model is quite large and can be slow on CPU.\n",
        "    # Consider using a smaller model or enabling a GPU runtime in Colab for faster processing.\n",
        "    model_name = \"tiiuae/Falcon-H1-1B-Base\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        device_map=\"auto\",\n",
        "        torch_dtype=torch.bfloat16\n",
        "    )\n",
        "    pipe = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        max_new_tokens=512,\n",
        "        do_sample=False  # Deteministic output to reduce hallucination\n",
        "    )\n",
        "    print(\"GPU detected.\" if torch.cuda.is_available() else \"⚠️ GPU not detected. Using CPU.\")\n",
        "    return HuggingFacePipeline(pipeline=pipe), model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37f5ba52"
      },
      "source": [
        "# -------- Prompt Template --------\n",
        "prompt_template = \"\"\"You are an assistant for the Oman Central Bank. You must follow these rules strictly:\n",
        "\n",
        "RULES:\n",
        "1. Use ONLY the information provided in the Context section below\n",
        "2. If the exact answer is not found in the Context, respond with \"I don't have that specific information available\"\n",
        "3. Do NOT add any information from your general knowledge\n",
        "4. Do NOT make assumptions or inferences beyond what is explicitly stated\n",
        "5. Quote directly from the context when possible\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Instructions: Read the context carefully and provide an answer using ONLY the information above. If you cannot find the answer in the context, say \"I don't have that specific information available.\"\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(input_variables=[\"context\", \"question\"], template=prompt_template)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b9c68a9"
      },
      "source": [
        "# -------- Oman Central Bank RAG --------\n",
        "class OmanCBRAG:\n",
        "    def __init__(self):\n",
        "        self.processor = DocumentProcessor()\n",
        "        self.tagger = DepartmentTagger()\n",
        "        self.embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
        "        self.vector_store = None\n",
        "        self.llm, self.model = get_llm()\n",
        "        self.qa_chain = None\n",
        "\n",
        "    def ingest_documents(self, folder_path):\n",
        "        documents = []\n",
        "        subfolder = 'cbo currency data set'\n",
        "        extracted_files_path = os.path.join(folder_path, subfolder)\n",
        "\n",
        "        if not os.path.isdir(extracted_files_path):\n",
        "            print(f\"⚠️ Expected folder path but got: {extracted_files_path}\")\n",
        "            return\n",
        "\n",
        "        # Process files in the extracted folder\n",
        "        for filename in os.listdir(extracted_files_path):\n",
        "            file_path = os.path.join(extracted_files_path, filename)\n",
        "            file_extension = os.path.splitext(filename)[1].lower()\n",
        "\n",
        "            if file_extension == \".pdf\":\n",
        "                _, text_en, sum_en, sum_ar = self.processor.process_document(file_path, 'pdf')\n",
        "            elif file_extension == \".txt\":\n",
        "                 _, text_en, sum_en, sum_ar = self.processor.process_document(file_path, 'txt')\n",
        "            elif file_extension == \".md\":\n",
        "                 _, text_en, sum_en, sum_ar = self.processor.process_document(file_path, 'md')\n",
        "            else:\n",
        "                print(f\"Skipping unsupported file type: {filename}\")\n",
        "                continue\n",
        "\n",
        "            departments = self.tagger.tag(text_en)\n",
        "            splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)\n",
        "            chunks = splitter.split_text(text_en)\n",
        "            for chunk in chunks:\n",
        "                documents.append(Document(\n",
        "                    page_content=chunk,\n",
        "                    metadata={\n",
        "                        \"filename\": filename,\n",
        "                        \"summary_en\": sum_en,\n",
        "                        \"summary_ar\": sum_ar,\n",
        "                        \"departments\": departments\n",
        "                    }\n",
        "                ))\n",
        "\n",
        "        # Process additional files outside the zip\n",
        "        additional_files = [\"/content/banking_knowledge.txt\", \"/content/cbo_faq_mapping.md\"]\n",
        "        for file_path in additional_files:\n",
        "            if os.path.exists(file_path):\n",
        "                filename = os.path.basename(file_path)\n",
        "                file_extension = os.path.splitext(filename)[1].lower()\n",
        "\n",
        "                if file_extension == \".txt\":\n",
        "                    _, text_en, sum_en, sum_ar = self.processor.process_document(file_path, 'txt')\n",
        "                elif file_extension == \".md\":\n",
        "                    _, text_en, sum_en, sum_ar = self.processor.process_document(file_path, 'md')\n",
        "                else:\n",
        "                    print(f\"Skipping unsupported additional file type: {filename}\")\n",
        "                    continue\n",
        "\n",
        "                departments = self.tagger.tag(text_en)\n",
        "                splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)\n",
        "                chunks = splitter.split_text(text_en)\n",
        "                for chunk in chunks:\n",
        "                    documents.append(Document(\n",
        "                        page_content=chunk,\n",
        "                        metadata={\n",
        "                            \"filename\": filename,\n",
        "                            \"summary_en\": sum_en,\n",
        "                            \"summary_ar\": sum_ar,\n",
        "                            \"departments\": departments\n",
        "                        }\n",
        "                    ))\n",
        "\n",
        "\n",
        "        if not documents:\n",
        "            print(f\"⚠️ No documents processed from folder: {extracted_files_path} and additional files.\")\n",
        "            return\n",
        "\n",
        "        self.vector_store = FAISS.from_documents(documents, self.embeddings)\n",
        "        self.qa_chain = RetrievalQA.from_chain_type(\n",
        "            llm=self.llm,\n",
        "            chain_type=\"stuff\",\n",
        "            retriever=self.vector_store.as_retriever(),\n",
        "            chain_type_kwargs={\"prompt\": prompt},\n",
        "            return_source_documents=False,\n",
        "        )\n",
        "        print(f\"✅ Indexed {len(documents)} chunks and initialized QA chain\")\n",
        "\n",
        "    def save_weights(self, path=\"falcon_h1_weights.pth\"):\n",
        "        if self.model:\n",
        "            torch.save(self.model.state_dict(), path)\n",
        "            print(f\"✅ Model weights saved to {path}\")\n",
        "        else:\n",
        "            print(\"❌ Model not initialized. Cannot save weights.\")\n",
        "\n",
        "\n",
        "    def query(self, question, language='en'):\n",
        "        if not self.qa_chain:\n",
        "            print(\"❌ QA chain not initialized. Please ingest documents first.\")\n",
        "            return \"Please ingest documents first.\", \"\"\n",
        "\n",
        "        print(f\"Received question in {language}: {question}\")\n",
        "\n",
        "        translated_question = question\n",
        "        if language == 'ar':\n",
        "            try:\n",
        "                translated_question = self.processor.translate_text_in_chunks(question, dest='en')\n",
        "                print(f\"Translated question to English: {translated_question}\")\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error translating question: {e}\")\n",
        "                return \"Error translating your question.\", \"\"\n",
        "\n",
        "        try:\n",
        "            result = self.qa_chain.invoke({\"query\": translated_question})\n",
        "            answer_en = result[\"result\"]\n",
        "            print(f\"Generated English answer: {answer_en}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error generating answer: {e}\")\n",
        "            return \"An error occurred during answer generation.\", \"\"\n",
        "\n",
        "        if language == 'ar':\n",
        "            try:\n",
        "                answer_ar = self.processor.translate_text_in_chunks(answer_en, dest='ar')\n",
        "                print(f\"Translated answer to Arabic: {answer_ar}\")\n",
        "                return answer_ar, answer_en\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error translating answer back to Arabic: {e}\")\n",
        "                return \"Error translating the answer.\", answer_en\n",
        "        else:\n",
        "            return answer_en, answer_en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22608214"
      },
      "source": [
        "# Initialize and ingest\n",
        "rag = OmanCBRAG()\n",
        "rag.ingest_documents(extract_dir)\n",
        "rag.save_weights()\n",
        "\n",
        "# Query function without UI\n",
        "def query_without_ui(question, language='en'):\n",
        "    answer, answer_en = rag.query(question, language)\n",
        "    if language == 'ar':\n",
        "        print(f\"الإجابة بالعربية:\\n{answer}\\n\\n(English answer for reference: {answer_en})\")\n",
        "    else:\n",
        "        print(f\"English answer:\\n{answer}\")\n",
        "\n",
        "# Example query\n",
        "query_without_ui(\"What is the current banking regulation framework in Oman?\", language='en')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{% extends "base.html" %}

{% block title %}AI Assistant Chat{% endblock %}

{% block main_class %}{% endblock %}

{% block content %}
<div class="flex h-screen bg-gray-50">
    <!-- Chat History Sidebar -->
    <div class="w-80 bg-white shadow-lg border-r border-gray-200 flex flex-col hidden lg:flex">
        <!-- Sidebar Header -->
        <div class="p-4 border-b border-gray-200">
            <h2 class="text-lg font-semibold text-gray-900 flex items-center">
                <i class="fas fa-history text-ocb-blue mr-2"></i>
                Chat History
            </h2>
            <button id="newChatBtn" class="mt-2 w-full bg-ocb-blue text-white px-3 py-2 rounded-md text-sm font-medium hover:bg-blue-700 transition-colors">
                <i class="fas fa-plus mr-2"></i>New Chat
            </button>
        </div>
        
        <!-- Chat History List -->
        <div id="chatHistoryList" class="flex-1 overflow-y-auto p-4 space-y-2">
            <!-- Chat history items will be loaded here -->
            <div class="text-center text-gray-500 py-8">
                <i class="fas fa-comments text-2xl mb-2"></i>
                <p class="text-sm">No chat history yet</p>
            </div>
        </div>
    </div>

    <!-- Main Chat Area -->
    <div class="flex-1 flex flex-col">
        <!-- Header -->
        <div class="bg-white border-b border-gray-200 px-6 py-4">
            <div class="flex items-center justify-between">
                <div>
                    <h1 class="text-2xl font-bold text-gray-900">
                        <i class="fas fa-comments text-ocb-blue mr-3"></i>
                        AI Assistant Chat
                    </h1>
                    <p class="mt-1 text-gray-600 text-sm">
                        Chat with the AI assistant about your department's documents
                    </p>
                </div>
                <!-- Mobile Menu Button -->
                <button id="mobileMenuBtn" class="lg:hidden inline-flex items-center px-3 py-2 border border-gray-300 text-sm font-medium rounded-md text-gray-700 bg-white hover:bg-gray-50">
                    <i class="fas fa-history mr-2"></i>
                    History
                </button>
            </div>
        </div>

        <!-- Chat Messages -->
        <div class="flex-1 overflow-y-auto p-6">
            <div id="chatMessages" class="space-y-4 max-w-4xl mx-auto">
                {% if messages %}
                    {% for message in messages %}
                    <div class="flex {% if message.type == 'user' %}justify-end{% else %}justify-start{% endif %}">
                        <div class="max-w-xs lg:max-w-md px-4 py-2 rounded-lg {% if message.type == 'user' %}bg-ocb-blue text-white{% else %}bg-gray-100 text-gray-800{% endif %}">
                            {% if message.type == 'assistant' %}
                            <div class="flex items-center mb-1">
                                <i class="fas fa-robot text-ocb-blue mr-2"></i>
                                <span class="text-xs font-medium">AI Assistant</span>
                            </div>
                            {% endif %}
                                    <div class="text-sm prose prose-sm max-w-none">{{ message.content|markdown|safe }}</div>
                        </div>
                    </div>
                    {% endfor %}
                {% else %}
                <div class="text-center text-gray-500 py-12">
                    <i class="fas fa-comments text-4xl mb-4"></i>
                    <p class="text-lg">Start a conversation with the AI assistant</p>
                    <p class="text-sm mt-2">Ask questions about your department's documents</p>
                </div>
                {% endif %}
            </div>
        </div>

        <!-- Chat Input Area -->
        <div class="bg-white border-t border-gray-200 p-6">
            <form method="POST" id="chatForm" class="max-w-4xl mx-auto space-y-4">
                <!-- File Upload Area -->
                <div id="fileUploadArea" class="hidden">
                    <div class="border border-gray-300 border-dashed rounded-lg p-4">
                        <div class="flex items-center justify-between">
                            <div class="flex items-center space-x-2">
                                <i class="fas fa-file text-gray-400"></i>
                                <span class="text-sm text-gray-600" id="uploadedFileName">No file selected</span>
                            </div>
                            <button type="button" id="removeFileBtn" class="text-red-500 hover:text-red-700 text-sm">
                                <i class="fas fa-times"></i>
                            </button>
                        </div>
                    </div>
                </div>

                <!-- Compact Audio Recording -->
                <div class="flex items-center justify-center">
                    <button type="button" id="recordBtn" onclick="toggleRecording()" 
                            class="inline-flex items-center px-3 py-2 border border-gray-300 text-sm font-medium rounded-md text-gray-700 bg-white hover:bg-gray-50 transition-colors duration-200">
                        <i class="fas fa-microphone text-red-600 mr-2" id="recordIcon"></i>
                        <span id="recordBtnLabel">Record</span>
                    </button>
                    <span id="recordTimer" class="ml-2 text-sm text-gray-600 font-mono">00:00 / 01:00</span>
                    <div id="recordingStatus" class="ml-2 text-xs text-gray-500"></div>
                </div>

                <!-- Compact Waveform (only show when recording) -->
                <div id="waveformContainer" class="hidden">
                    <canvas id="waveformCanvas" width="600" height="32" 
                            class="w-full bg-gray-50 border border-gray-200 rounded" 
                            style="height: 32px;"></canvas>
                </div>


                <!-- Message Input -->
                <div class="flex items-end space-x-4">
                    <!-- File Upload Button -->
                    <button type="button" id="uploadBtn" class="flex-shrink-0 inline-flex items-center px-3 py-2 border border-gray-300 text-sm font-medium rounded-md text-gray-700 bg-white hover:bg-gray-50 transition-colors">
                        <i class="fas fa-paperclip mr-2"></i>
                        Upload
                    </button>
                    <input type="file" id="fileInput" accept=".pdf,.docx,.doc,.png,.jpg,.jpeg,.tiff" class="hidden">
                    
                    <!-- Message Input -->
                    <div class="flex-1">
                        <label for="message" class="sr-only">Message</label>
                        <textarea name="message" id="message" rows="2" 
                                  class="shadow-sm focus:ring-ocb-blue focus:border-ocb-blue block w-full sm:text-sm border-gray-300 rounded-md resize-none"
                                  placeholder="Ask a question about your department's documents..."
                                  required></textarea>
                    </div>
                    
                    <!-- Language and Send -->
                    <div class="flex flex-col space-y-2">
                        <select name="language" id="language" class="block w-24 pl-3 pr-8 py-2 text-base border-gray-300 focus:outline-none focus:ring-ocb-blue focus:border-ocb-blue sm:text-sm rounded-md">
                            <option value="en">EN</option>
                            <option value="ar">AR</option>
                        </select>
                        <button type="submit" class="inline-flex items-center px-4 py-2 border border-transparent text-sm font-medium rounded-md text-white bg-ocb-blue hover:bg-blue-700 transition-colors duration-200">
                            <i class="fas fa-paper-plane mr-2"></i>
                            Send
                        </button>
                    </div>
                </div>
            </form>
        </div>
    </div>
</div>
{% endblock %}

{% block scripts %}
<!-- Include browser audio processor as fallback -->
<script src="{{ url_for('static', filename='browser_audio_processor.js') }}"></script>
<!-- Include markdown parser for dynamic content -->
<script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
<script>
(function() {
    'use strict';
    
    // Elements
    const recordBtn = document.getElementById('recordBtn');
    const recordBtnLabel = document.getElementById('recordBtnLabel');
    const recordIcon = document.getElementById('recordIcon');
    const recordTimer = document.getElementById('recordTimer');
    const recordingStatus = document.getElementById('recordingStatus');
    const canvas = document.getElementById('waveformCanvas');
    const messageTextarea = document.getElementById('message');
    
    // New UI elements
    const waveformContainer = document.getElementById('waveformContainer');
    const uploadBtn = document.getElementById('uploadBtn');
    const fileInput = document.getElementById('fileInput');
    const fileUploadArea = document.getElementById('fileUploadArea');
    const uploadedFileName = document.getElementById('uploadedFileName');
    const removeFileBtn = document.getElementById('removeFileBtn');
    const newChatBtn = document.getElementById('newChatBtn');
    const chatHistoryList = document.getElementById('chatHistoryList');
    
    // File upload functionality
    let selectedFile = null;
    
    uploadBtn.addEventListener('click', () => {
        fileInput.click();
    });
    
    fileInput.addEventListener('change', (e) => {
        const file = e.target.files[0];
        if (file) {
            selectedFile = file;
            uploadedFileName.textContent = file.name;
            fileUploadArea.classList.remove('hidden');
        }
    });
    
    removeFileBtn.addEventListener('click', () => {
        selectedFile = null;
        fileInput.value = '';
        fileUploadArea.classList.add('hidden');
        uploadedFileName.textContent = 'No file selected';
    });
    
    // New chat functionality
    newChatBtn.addEventListener('click', async () => {
        try {
            // Call API to start new chat session
            const response = await fetch('/api/new-chat', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                }
            });
            
            if (response.ok) {
                // Clear current chat display
                document.getElementById('chatMessages').innerHTML = `
                    <div class="text-center text-gray-500 py-12">
                        <i class="fas fa-comments text-4xl mb-4"></i>
                        <p class="text-lg">Start a conversation with the AI assistant</p>
                        <p class="text-sm mt-2">Ask questions about your department's documents</p>
                    </div>
                `;
                
                // Clear message input
                messageTextarea.value = '';
                
                // Remove selected file
                removeFileBtn.click();
                
                // Load updated chat history
                loadChatHistory();
            } else {
                console.error('Failed to start new chat session');
            }
        } catch (error) {
            console.error('Error starting new chat:', error);
        }
    });
    
    // Load chat history
    function loadChatHistory() {
        fetch('/api/chat-history')
            .then(response => response.json())
            .then(data => {
                if (data.success && data.chats.length > 0) {
                    chatHistoryList.innerHTML = '';
                    data.chats.forEach(chat => {
                        const chatItem = document.createElement('div');
                        chatItem.className = 'p-3 border border-gray-200 rounded-lg hover:bg-gray-50 cursor-pointer transition-colors';
                        chatItem.innerHTML = `
                            <div class="text-sm font-medium text-gray-900 truncate">${chat.summary || 'Untitled Chat'}</div>
                            <div class="text-xs text-gray-500 mt-1">${new Date(chat.timestamp).toLocaleDateString()}</div>
                        `;
                        chatItem.addEventListener('click', () => loadChat(chat.id));
                        chatHistoryList.appendChild(chatItem);
                    });
                } else {
                    chatHistoryList.innerHTML = `
                        <div class="text-center text-gray-500 py-8">
                            <i class="fas fa-comments text-2xl mb-2"></i>
                            <p class="text-sm">No chat history yet</p>
                        </div>
                    `;
                }
            })
            .catch(error => {
                console.error('Error loading chat history:', error);
            });
    }
    
    // Load specific chat
    function loadChat(chatId) {
        fetch(`/api/chat-history/${chatId}`)
            .then(response => response.json())
            .then(data => {
                if (data.success) {
                    const messagesContainer = document.getElementById('chatMessages');
                    messagesContainer.innerHTML = '';
                    
                    if (data.messages.length > 0) {
                        data.messages.forEach(message => {
                            const messageDiv = document.createElement('div');
                            messageDiv.className = `flex ${message.type === 'user' ? 'justify-end' : 'justify-start'}`;
                            messageDiv.innerHTML = `
                                <div class="max-w-xs lg:max-w-md px-4 py-2 rounded-lg ${message.type === 'user' ? 'bg-ocb-blue text-white' : 'bg-gray-100 text-gray-800'}">
                                    ${message.type === 'assistant' ? `
                                        <div class="flex items-center mb-1">
                                            <i class="fas fa-robot text-ocb-blue mr-2"></i>
                                            <span class="text-xs font-medium">AI Assistant</span>
                                        </div>
                                    ` : ''}
                                    <div class="text-sm prose prose-sm max-w-none">${marked.parse(message.content)}</div>
                                </div>
                            `;
                            messagesContainer.appendChild(messageDiv);
                        });
                    } else {
                        messagesContainer.innerHTML = `
                            <div class="text-center text-gray-500 py-12">
                                <i class="fas fa-comments text-4xl mb-4"></i>
                                <p class="text-lg">Start a conversation with the AI assistant</p>
                                <p class="text-sm mt-2">Ask questions about your department's documents</p>
                            </div>
                        `;
                    }
                    
                    // Scroll to bottom
                    messagesContainer.scrollTop = messagesContainer.scrollHeight;
                }
            })
            .catch(error => {
                console.error('Error loading chat:', error);
            });
    }
    
    // Load chat history on page load
    loadChatHistory();
    
    // Mobile menu functionality
    const mobileMenuBtn = document.getElementById('mobileMenuBtn');
    const sidebar = document.querySelector('.w-80');
    
    if (mobileMenuBtn && sidebar) {
        mobileMenuBtn.addEventListener('click', () => {
            sidebar.classList.toggle('hidden');
            sidebar.classList.toggle('absolute');
            sidebar.classList.toggle('z-50');
            sidebar.classList.toggle('lg:flex');
        });
    }
    
    // Handle form submission with file upload
    document.getElementById('chatForm').addEventListener('submit', async (e) => {
        e.preventDefault();
        
        const message = messageTextarea.value.trim();
        const language = document.getElementById('language').value;
        
        if (!message && !selectedFile) {
            alert('Please enter a message or upload a file');
            return;
        }
        
        // Show loading state
        const submitBtn = e.target.querySelector('button[type="submit"]');
        const originalText = submitBtn.innerHTML;
        submitBtn.innerHTML = '<i class="fas fa-spinner fa-spin mr-2"></i>Sending...';
        submitBtn.disabled = true;
        
        try {
            const formData = new FormData();
            formData.append('message', message);
            formData.append('language', language);
            
            if (selectedFile) {
                formData.append('file', selectedFile);
            }
            
            const response = await fetch('/chat', {
                method: 'POST',
                body: formData
            });
            
            if (response.ok) {
                // Reload the page to show the new message
                window.location.reload();
            } else {
                throw new Error('Failed to send message');
            }
        } catch (error) {
            console.error('Error sending message:', error);
            alert('Failed to send message. Please try again.');
        } finally {
            // Reset button state
            submitBtn.innerHTML = originalText;
            submitBtn.disabled = false;
        }
    });
    
    // Initialize fallback audio processor
    let fallbackProcessor = null;
    let whisperHandler = null;
    
    try {
        if (window.AudioProcessor && window.WhisperAudioHandler) {
            fallbackProcessor = new window.AudioProcessor();
            whisperHandler = new window.WhisperAudioHandler();
            console.log('[voice] Fallback audio processor initialized');
        } else {
            console.warn('[voice] Fallback audio processor not available');
        }
    } catch (error) {
        console.error('[voice] Failed to initialize fallback audio processor:', error);
    }

    // Expose a safe default for onclick even if initialization fails early
    window.toggleRecording = async function() {
        console.warn('[voice] toggleRecording called before initialization');
    };

    if (!recordBtn || !recordTimer || !canvas) {
        console.error('[voice] Required elements not found');
        return; // leave the noop toggleRecording in place
    }

    const canvasCtx = canvas.getContext('2d');
    let isRecording = false;
    let startTime = 0;
    let timerInterval = null;
    let rafId = null;

    // Media
    let mediaStream = null;
    let mediaRecorder = null;
    let audioContext = null;
    let analyser = null;
    let source = null;
    let dataArray = null;
    let bufferLength = 0;

    // Server session
    let voiceSessionId = null;
    let recordedChunks = [];

    function formatTime(ms) {
        const totalSec = Math.min(60, Math.floor(ms / 1000));
        const mm = String(Math.floor(totalSec / 60)).padStart(2, '0');
        const ss = String(totalSec % 60).padStart(2, '0');
        return `${mm}:${ss} / 01:00`;
    }

    function clearCanvas() {
        if (!canvasCtx) return;
        canvasCtx.clearRect(0, 0, canvas.width, canvas.height);
        canvasCtx.fillStyle = '#f9fafb';
        canvasCtx.fillRect(0, 0, canvas.width, canvas.height);
    }

    function resizeCanvas() {
        const rect = canvas.getBoundingClientRect();
        const dpr = window.devicePixelRatio || 1;
        console.log('[voice] resizeCanvas rect.width=', rect.width, 'dpr=', dpr);
        
        // Set actual canvas pixel size (compact 32px height)
        canvas.width = Math.max(600, Math.floor(rect.width * dpr));
        canvas.height = Math.floor(32 * dpr);
        
        // Reset and scale the drawing context (avoid cumulative scaling)
        canvasCtx.setTransform(1, 0, 0, 1, 0, 0);
        canvasCtx.scale(dpr, dpr);
        
        // CSS display size (compact)
        canvas.style.width = rect.width + 'px';
        canvas.style.height = '32px';
        
        clearCanvas();
    }

    function drawWaveform() {
        if (!analyser || !dataArray || !isRecording) return;
        
        try {
            analyser.getByteTimeDomainData(dataArray);

            // Clear canvas
            canvasCtx.fillStyle = '#f9fafb';
            canvasCtx.fillRect(0, 0, canvas.width / (window.devicePixelRatio || 1), canvas.height / (window.devicePixelRatio || 1));

            // Draw waveform (compact version)
            canvasCtx.lineWidth = 1;
            canvasCtx.strokeStyle = '#1e40af';
            canvasCtx.beginPath();

            const sliceWidth = (canvas.width / (window.devicePixelRatio || 1)) / bufferLength;
            let x = 0;
            const centerY = (canvas.height / (window.devicePixelRatio || 1)) / 2;

            for (let i = 0; i < bufferLength; i++) {
                const v = dataArray[i] / 128.0;
                const y = centerY + (v * 10); // Smaller amplitude for compact display

                if (i === 0) {
                    canvasCtx.moveTo(x, y);
                } else {
                    canvasCtx.lineTo(x, y);
                }

                x += sliceWidth;
            }

            canvasCtx.lineTo(canvas.width / (window.devicePixelRatio || 1), centerY);
            canvasCtx.stroke();

            rafId = requestAnimationFrame(drawWaveform);
        } catch (error) {
            console.error('[voice] Waveform drawing error:', error);
        }
    }

    function updateButtonState(recording) {
        if (recording) {
            recordBtn.classList.remove('border-gray-300', 'text-gray-700', 'bg-white', 'hover:bg-gray-50');
            recordBtn.classList.add('bg-red-600', 'hover:bg-red-700', 'text-white', 'border-red-600');
            recordBtnLabel.textContent = 'Stop';
            recordIcon.classList.remove('fa-microphone', 'text-red-600');
            recordIcon.classList.add('fa-stop', 'text-white');
            recordingStatus.textContent = 'Recording...';
            recordingStatus.classList.add('text-red-600');
            
            // Show waveform container
            waveformContainer.classList.remove('hidden');
        } else {
            recordBtn.classList.remove('bg-red-600', 'hover:bg-red-700', 'text-white', 'border-red-600');
            recordBtn.classList.add('border-gray-300', 'text-gray-700', 'bg-white', 'hover:bg-gray-50');
            recordBtnLabel.textContent = 'Record';
            recordIcon.classList.remove('fa-stop', 'text-white');
            recordIcon.classList.add('fa-microphone', 'text-red-600');
            recordingStatus.textContent = '';
            recordingStatus.classList.remove('text-red-600');
            
            // Hide waveform container
            waveformContainer.classList.add('hidden');
        }
    }

    async function startRecording() {
        try {
            recordBtn.disabled = true;
            recordingStatus.textContent = 'Starting...';
            console.log('[voice] startRecording invoked');
            
            // Check browser support
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                throw new Error('Microphone access not supported by this browser');
            }

            // Start server voice session (if available)
            try {
                const res = await fetch('/voice/start', { method: 'POST' });
                if (res.ok) {
                    const data = await res.json();
                    voiceSessionId = data.session_id;
                    console.log('[voice] session started, id=', voiceSessionId);
                }
            } catch (error) {
                console.log('[voice] session start not available, proceeding locally:', error);
            }

            // Get microphone access
            mediaStream = await navigator.mediaDevices.getUserMedia({ 
                audio: {
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true
                }
            });
            console.log('[voice] getUserMedia acquired');

            // Create audio context for visualization
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            
            if (audioContext.state === 'suspended') {
                await audioContext.resume();
                console.log('[voice] audioContext resumed');
            }

            analyser = audioContext.createAnalyser();
            source = audioContext.createMediaStreamSource(mediaStream);
            source.connect(analyser);
            
            analyser.fftSize = 2048;
            // Use fftSize for time-domain buffer length
            bufferLength = analyser.fftSize;
            dataArray = new Uint8Array(bufferLength);
            console.log('[voice] analyser configured, bufferLength=', bufferLength);

            // Setup media recorder
            const options = {};
            if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
                options.mimeType = 'audio/webm;codecs=opus';
            } else if (MediaRecorder.isTypeSupported('audio/webm')) {
                options.mimeType = 'audio/webm';
            }

            // Ensure a supported MIME type; handle Edge/Firefox variations
            try {
                mediaRecorder = new MediaRecorder(mediaStream, options);
            } catch (e) {
                console.warn('[voice] MediaRecorder init failed with options, retrying without:', e);
                mediaRecorder = new MediaRecorder(mediaStream);
            }
            recordedChunks = [];

            mediaRecorder.ondataavailable = (event) => {
                if (event.data && event.data.size > 0) {
                    recordedChunks.push(event.data);
                    console.log('[voice] chunk size=', event.data.size);
                }
            };
            mediaRecorder.onerror = (e) => console.error('[voice] MediaRecorder error:', e);
            mediaRecorder.onstart = () => console.log('[voice] MediaRecorder started');
            mediaRecorder.onstop = () => console.log('[voice] MediaRecorder stopped');

            // Collect data and upload once on stop
            mediaRecorder.start();
            console.log('[voice] mediaRecorder.start called');

            // Start recording state
            isRecording = true;
            startTime = Date.now();
            updateButtonState(true);
            
            resizeCanvas();
            drawWaveform();

            // Start timer
            timerInterval = setInterval(async () => {
                const elapsed = Date.now() - startTime;
                recordTimer.textContent = formatTime(elapsed);
                
                if (elapsed >= 60000) {
                    console.log('[voice] auto stop at 60s');
                    await stopRecording();
                }
            }, 100);

            recordBtn.disabled = false;

        } catch (error) {
            console.error('[voice] Failed to start recording:', error);
            recordingStatus.textContent = `Error: ${error.message}`;
            recordingStatus.classList.add('text-red-600');
            
            // Cleanup on error
            await cleanup();
            recordBtn.disabled = false;
        }
    }

    async function stopRecording() {
        if (!isRecording) return;
        
        isRecording = false;
        updateButtonState(false);
        recordingStatus.textContent = 'Processing...';
        console.log('[voice] stopRecording invoked');

        try {
            // Stop media recorder
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                await new Promise((resolve) => {
                    mediaRecorder.onstop = resolve;
                    mediaRecorder.stop();
                });
            }

            // Upload full recording and get transcript in one request (before cleanup)
            try {
                if (!recordedChunks || recordedChunks.length === 0) {
                    throw new Error('no audio captured');
                }
                
                // Try primary transcription method first
                let transcriptionSuccess = false;
                try {
                    // Prefer WAV when ffmpeg is unavailable on server
                    let chosenMime = (mediaRecorder && mediaRecorder.mimeType) ? mediaRecorder.mimeType : '';
                    let ext = 'webm';
                    if (chosenMime.includes('wav')) {
                        ext = 'wav';
                    } else if (chosenMime.includes('webm')) {
                        ext = 'webm';
                    } else if (chosenMime.includes('ogg')) {
                        ext = 'ogg';
                    }
                    // If server lacks ffmpeg, WAV is safest; attempt to convert
                    // Some browsers do not support WAV via MediaRecorder; if not, keep chosenMime
                    if (!chosenMime) {
                        chosenMime = 'audio/webm';
                    }
                    // Convert to WAV in-browser to avoid server ffmpeg/librosa issues
                    const originalBlob = new Blob(recordedChunks, { type: chosenMime });
                    let wavBuffer = null;
                    if (fallbackProcessor) {
                        try {
                            const conv = await fallbackProcessor.blobToWhisperFormat(originalBlob);
                            if (conv && conv.success && conv.audioData) {
                                wavBuffer = conv.audioData;
                                ext = 'wav';
                                chosenMime = 'audio/wav';
                                console.log('[voice] Converted recording to WAV in-browser');
                            }
                        } catch (ce) {
                            console.warn('[voice] In-browser WAV conversion failed, sending original blob', ce);
                        }
                    }

                    const uploadBlob = wavBuffer ? new Blob([wavBuffer], { type: 'audio/wav' }) : originalBlob;
                    const sr = audioContext ? audioContext.sampleRate : '';
                    const formData = new FormData();
                    formData.append('sample_rate_hz', String(sr));
                    formData.append('audio', uploadBlob, `recording.${ext}`);
                    const response = await fetch('/voice/transcribe', { method: 'POST', body: formData });
                    if (response.ok) {
                        const result = await response.json();
                        if (result.transcript) {
                            messageTextarea.value = result.transcript;
                            console.log('[voice] Primary transcription successful:', result.transcript);
                            transcriptionSuccess = true;
                        } else {
                            console.log('[voice] Primary transcription empty; details:', result);
                        }
                    } else {
                        console.error('[voice] Primary /voice/transcribe HTTP error', response.status);
                    }
                } catch (primaryError) {
                    console.error('[voice] Primary transcription failed:', primaryError);
                }
                
                // Fallback to browser audio processor if primary method failed
                if (!transcriptionSuccess && fallbackProcessor && whisperHandler) {
                    try {
                        console.log('[voice] Attempting fallback transcription with browser processor');
                        const blob = new Blob(recordedChunks, { type: 'audio/webm' });
                        const result = await whisperHandler.processRecordedAudio(blob);
                        if (result.success && result.transcript) {
                            messageTextarea.value = result.transcript;
                            console.log('[voice] Fallback transcription successful:', result.transcript);
                            transcriptionSuccess = true;
                        } else {
                            console.error('[voice] Fallback transcription failed:', result.error);
                        }
                    } catch (fallbackError) {
                        console.error('[voice] Fallback transcription error:', fallbackError);
                    }
                }
                
                if (!transcriptionSuccess) {
                    console.warn('[voice] All transcription methods failed');
                    recordingStatus.textContent = 'Transcription failed - please try again';
                }
                
            } catch (err) {
                console.error('[voice] Audio processing error:', err);
                recordingStatus.textContent = 'Audio processing failed';
            }

            await cleanup();

            recordingStatus.textContent = 'Complete';
            setTimeout(() => {
                recordingStatus.textContent = '';
            }, 2000);

        } catch (error) {
            console.error('Error stopping recording:', error);
            recordingStatus.textContent = 'Error stopping recording';
        }
    }

    async function cleanup() {
        // Stop animation
        if (rafId) {
            cancelAnimationFrame(rafId);
            rafId = null;
        }

        // Clear timer
        if (timerInterval) {
            clearInterval(timerInterval);
            timerInterval = null;
        }

        // Close media stream
        if (mediaStream) {
            mediaStream.getTracks().forEach(track => track.stop());
            mediaStream = null;
        }

        // Close audio context
        if (audioContext && audioContext.state !== 'closed') {
            try {
                await audioContext.close();
            } catch (error) {
                console.error('[voice] Error closing audio context:', error);
            }
            audioContext = null;
        }

        // Reset UI
        recordTimer.textContent = '00:00 / 01:00';
        clearCanvas();
        
        // Clean up references
        analyser = null;
        source = null;
        dataArray = null;
        mediaRecorder = null;
    }

    // Global function for button click (override safe default once ready)
    window.toggleRecording = async function() {
        if (isRecording) {
            await stopRecording();
        } else {
            await startRecording();
        }
    };

    // Initialize
    window.addEventListener('resize', resizeCanvas);
    resizeCanvas();
    
    // Test canvas drawing on load
    setTimeout(() => {
        clearCanvas();
        // Draw a test line to verify canvas is working
        canvasCtx.strokeStyle = '#e5e7eb';
        canvasCtx.lineWidth = 1;
        canvasCtx.beginPath();
        canvasCtx.moveTo(0, canvas.height / (window.devicePixelRatio || 1) / 2);
        canvasCtx.lineTo(canvas.width / (window.devicePixelRatio || 1), canvas.height / (window.devicePixelRatio || 1) / 2);
        canvasCtx.stroke();
    }, 100);

})();
</script>
{% endblock %}
